## Tratamento e Modelagem dos dados: Avaliação da Qualidade do Ar e Poluição

<div style="text-align: center;">
  <img src="../images/data_creaning.png" alt="Texto alternativo" width="800">
</div>

Neste notebook faremos o tratamento dos dados, aplicaremos o pré-processamento e a aplicação de modelos de aprendizado de máquina, a fim de modelar a variável de qualidade do ar.

- No tratamento de dados foi necessário fazer modifições na coluna de temperatura, a justificava advem do (EDA);
- No pré-processamento foi aplicado a padronização StandardScaler para os nossos Features e o OrdinalEncoder para o nosso Targer(que é uma variável qualitativa ordinal).
- Na modelagem foram utilizados diversos modelos e foi realizado a combinação de modelos, o que resultou em um modelo ótimo, todos os modelos foram salvos em artifacts.


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Palette Setting
color_palette = ['#333333', '#4F4F4F', '#6B6B6B', '#878787', '#A3A3A3', '#BFBFBF']
# Setting as the palette
sns.set_palette(sns.color_palette(color_palette))
# Display
sns.color_palette(color_palette)
```




<svg  width="330" height="55"><rect x="0" y="0" width="55" height="55" style="fill:#333333;stroke-width:2;stroke:rgb(255,255,255)"/><rect x="55" y="0" width="55" height="55" style="fill:#4f4f4f;stroke-width:2;stroke:rgb(255,255,255)"/><rect x="110" y="0" width="55" height="55" style="fill:#6b6b6b;stroke-width:2;stroke:rgb(255,255,255)"/><rect x="165" y="0" width="55" height="55" style="fill:#878787;stroke-width:2;stroke:rgb(255,255,255)"/><rect x="220" y="0" width="55" height="55" style="fill:#a3a3a3;stroke-width:2;stroke:rgb(255,255,255)"/><rect x="275" y="0" width="55" height="55" style="fill:#bfbfbf;stroke-width:2;stroke:rgb(255,255,255)"/></svg>




```python
dataset = pd.read_csv("../input/data.csv", sep=',')
dataset.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>PM2.5</th>
      <th>PM10</th>
      <th>NO2</th>
      <th>SO2</th>
      <th>CO</th>
      <th>Proximity_to_Industrial_Areas</th>
      <th>Population_Density</th>
      <th>Air Quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>29.8</td>
      <td>59.1</td>
      <td>5.2</td>
      <td>17.9</td>
      <td>18.9</td>
      <td>9.2</td>
      <td>1.72</td>
      <td>6.3</td>
      <td>319</td>
      <td>Moderate</td>
    </tr>
    <tr>
      <th>1</th>
      <td>28.3</td>
      <td>75.6</td>
      <td>2.3</td>
      <td>12.2</td>
      <td>30.8</td>
      <td>9.7</td>
      <td>1.64</td>
      <td>6.0</td>
      <td>611</td>
      <td>Moderate</td>
    </tr>
  </tbody>
</table>
</div>



## 1. Tratamento dos dados

Nesta seção, iremos fazer ajustes no banco de dados. Faremos modificações de acordo com as incossistências obtidas na análise descritiva de dados (EDA).

### 1.2 Temperature

Na etapa da (EDA) foram achados valores a cima do valor de 100% de umidade, mas eram valores próximos a 100. Logo, utilizaremos o valor de 100% para os valores que estão a cima do valor de 100% de umidade.


```python
dataset[dataset['Temperature']>=100] = 100
```

## 2. Divisão em Treino e Teste


```python
features_names = ['Temperature', 'Humidity', 'PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'Proximity_to_Industrial_Areas',\
                  'Population_Density']

target_name = 'Air Quality'
```


```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(dataset[features_names], dataset[target_name],\
                                                     test_size=0.2, random_state=42)
```

## 3. Pré-Processamento


```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, StandardScaler

pipeline_features = Pipeline([
    ('scaler', StandardScaler())
])

pipeline_target = Pipeline([
    ('ordinal', OrdinalEncoder())  
])

X_train_scaled = pipeline_features.fit_transform(X_train)
X_test_scaled = pipeline_features.fit_transform(X_test)

y_train_encode = pipeline_target.fit_transform(np.array(y_train).reshape(-1,1))
y_test_encode = pipeline_target.fit_transform(np.array(y_test).reshape(-1,1))
```


```python
data = np.column_stack([X_train_scaled, y_train_encode])  

columns = ['Temperature', 'Humidity', 'PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'Proximity_to_Industrial_Areas',\
                  'Population_Density', 'Air Quality']
df = pd.DataFrame(data, columns=columns)

corr_matrix = df.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Matriz de Correlação entre FEATURES e TARGET')
plt.show()
```


    
![png](output_13_0.png)
    


## 4. Modelagem


```python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.neural_network import MLPClassifier
import xgboost as xgb


models = {
    'Logistic Regression': LogisticRegression(),
    'SVC': SVC(probability=True),
    'KNN Classifier': KNeighborsClassifier(),
    'Random Forest Classifier': RandomForestClassifier(),
    'Decision Tree Classifier': DecisionTreeClassifier(),
    'XGBoost': xgb.XGBClassifier(),  
    'MLP Classifier': MLPClassifier(max_iter=1000),  
}
```


```python
results = {}
predictions = {}
roc_auc_scores = {}
accuracy_scores = {}

for model_name, model in models.items():
    model.fit(X_train_scaled, y_train_encode.ravel())
    predicao = model.predict(X_test_scaled)
    predictions[model_name] = predicao
    probabilidade = model.predict_proba(X_test_scaled)

    roc_auc_scores[model_name] = roc_auc_score(y_test_encode.ravel(), probabilidade, multi_class='ovr', average='macro')
    accuracy_scores[model_name] = accuracy_score(y_test_encode.ravel(), predictions[model_name])
```


```python
roc_auc_scores
```




    {'Logistic Regression': np.float64(0.9919845257815304),
     'SVC': np.float64(0.993013461018295),
     'KNN Classifier': np.float64(0.9753343730681763),
     'Random Forest Classifier': np.float64(0.9940195168889585),
     'Decision Tree Classifier': np.float64(0.9262792131245001),
     'XGBoost': np.float64(0.9954519854498288),
     'MLP Classifier': np.float64(0.9928106445526784)}




```python
accuracy_scores
```




    {'Logistic Regression': 0.946,
     'SVC': 0.942,
     'KNN Classifier': 0.923,
     'Random Forest Classifier': 0.96,
     'Decision Tree Classifier': 0.914,
     'XGBoost': 0.956,
     'MLP Classifier': 0.954}




```python
best_combination = max(accuracy_scores, key=accuracy_scores.get)
best_score = accuracy_scores[best_combination]

print(f"A melhor previsão individual é: {best_combination}")
print(f'Melhor accuracy: {best_score:.4f}')
```

    A melhor previsão individual é: Random Forest Classifier
    Melhor accuracy: 0.9600
    


```python
from itertools import combinations
model_combinations = combinations(predictions.items(), 2)

accuracy_scores_combined = {}

for (model_name_1, pred_1), (model_name_2, pred_2) in model_combinations:
    combined_predictions = np.round((pred_1 + pred_2) / 2).astype(int)  
    accuracy_scores_combined[(model_name_1, model_name_2)] = accuracy_score(y_test_encode.ravel(), combined_predictions)

# Exibindo as acurácias das combinações
for model_comb, acc in accuracy_scores_combined.items():
    print(f"Combinação {model_comb}: Acurácia = {acc:.4f}")
```

    Combinação ('Logistic Regression', 'SVC'): Acurácia = 0.9420
    Combinação ('Logistic Regression', 'KNN Classifier'): Acurácia = 0.9180
    Combinação ('Logistic Regression', 'Random Forest Classifier'): Acurácia = 0.9450
    Combinação ('Logistic Regression', 'Decision Tree Classifier'): Acurácia = 0.9120
    Combinação ('Logistic Regression', 'XGBoost'): Acurácia = 0.9400
    Combinação ('Logistic Regression', 'MLP Classifier'): Acurácia = 0.9410
    Combinação ('SVC', 'KNN Classifier'): Acurácia = 0.9140
    Combinação ('SVC', 'Random Forest Classifier'): Acurácia = 0.9370
    Combinação ('SVC', 'Decision Tree Classifier'): Acurácia = 0.9100
    Combinação ('SVC', 'XGBoost'): Acurácia = 0.9380
    Combinação ('SVC', 'MLP Classifier'): Acurácia = 0.9370
    Combinação ('KNN Classifier', 'Random Forest Classifier'): Acurácia = 0.9170
    Combinação ('KNN Classifier', 'Decision Tree Classifier'): Acurácia = 0.8890
    Combinação ('KNN Classifier', 'XGBoost'): Acurácia = 0.9170
    Combinação ('KNN Classifier', 'MLP Classifier'): Acurácia = 0.9170
    Combinação ('Random Forest Classifier', 'Decision Tree Classifier'): Acurácia = 0.9260
    Combinação ('Random Forest Classifier', 'XGBoost'): Acurácia = 0.9520
    Combinação ('Random Forest Classifier', 'MLP Classifier'): Acurácia = 0.9470
    Combinação ('Decision Tree Classifier', 'XGBoost'): Acurácia = 0.9200
    Combinação ('Decision Tree Classifier', 'MLP Classifier'): Acurácia = 0.9180
    Combinação ('XGBoost', 'MLP Classifier'): Acurácia = 0.9430
    


```python
best_combination = max(accuracy_scores_combined, key=accuracy_scores_combined.get)
best_score = accuracy_scores_combined[best_combination]

print(f"A melhor combinação é: {', '.join(best_combination)}")
print(f'Melhor accuracy: {best_score:.4f}')
```

    A melhor combinação é: Random Forest Classifier, XGBoost
    Melhor accuracy: 0.9520
    

## 5. Salvando os melhores modelos


```python
import pickle
import os

os.makedirs('../artifacts', exist_ok=True)

with open('../artifacts/RandomForestClassifier.pkl', 'wb') as f:
    pickle.dump(models['Random Forest Classifier'], f)

with open('../artifacts/XGBoost.pkl', 'wb') as f:
    pickle.dump(models['XGBoost'], f)
```

## 6. Discurssão dos Resultados

Neste notebook, realizamos o tratamento de dados e a modelagem utilizando diferentes algoritmos de aprendizado de máquina. Os resultados obtidos foram bastante promissores, com acurácias superiores a 90%, o que sugere que tanto a modelagem quanto a metodologia aplicada são adequadas e eficazes para os dados em questão. Entre os modelos avaliados, o Random Forest Classifier se destacou como o mais eficiente. Além disso, uma abordagem combinada, utilizando a média simples das previsões do Random Forest Classifier e do XGBoost, apresentou um desempenho igualmente robusto, oferecendo uma solução potencialmente mais robusta e precisa.
